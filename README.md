# sirene-dataquality-monitor

Projet de **monitoring qualitÃ© de donnÃ©es** basÃ© sur les donnÃ©es publiques **SIRENE (INSEE)**, limitÃ© aux **Ã©tablissements du dÃ©partement 44 (Loire-Atlantique)**.

Le projet met en place un **pipeline reproductible** dans **Supabase (PostgreSQL)** avec :
- ingestion depuis CSV
- normalisation via vues SQL
- contrÃ´les qualitÃ© formalisÃ©s
- historisation des imports
- suivi qualitÃ© par import

Stack 100 % gratuite, orientÃ©e **data engineering / analytics**.

---

## ğŸ¯ Objectifs

- Importer les donnÃ©es SIRENE (INSEE)
- Filtrer le pÃ©rimÃ¨tre dÃ©partement 44
- Charger les donnÃ©es dans PostgreSQL (Supabase)
- Mettre en place un **monitoring qualitÃ© structurÃ©**
- PrÃ©parer une base propre pour analyses et dashboards

---

## ğŸ—‚ï¸ Structure du projet

sirene-dataquality-monitor/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # DonnÃ©es brutes INSEE (non versionnÃ©es)
â”‚ â””â”€â”€ processed/ # CSV filtrÃ© sirene_44.csv (non versionnÃ©)
â”œâ”€â”€ ingest/
â”‚ â”œâ”€â”€ filter_sirene_44.py
â”‚ â””â”€â”€ load_to_supabase.sh
â”œâ”€â”€ sql/
â”‚ â”œâ”€â”€ 001_view_v_sirene_44.sql
â”‚ â”œâ”€â”€ 010_dq_checks.sql
â”‚ â”œâ”€â”€ 020_view_v_sirene_44_analytics.sql
â”‚ â”œâ”€â”€ 030_create_dq_results.sql
â”‚ â”œâ”€â”€ 031_run_dq_rules.sql
â”‚ â”œâ”€â”€ 040_create_import_runs.sql
â”‚ â””â”€â”€ 050_view_v_dq_by_import.sql
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ run_pipeline.sh # Orchestration complÃ¨te du pipeline
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## âš™ï¸ PrÃ©requis

- Python 3.10+
- Client PostgreSQL (`psql`)
- AccÃ¨s Ã  une base PostgreSQL (Supabase)

Les dÃ©pendances Python sont listÃ©es dans `requirements.txt` (si utilisÃ©).

---

## ğŸ“¥ DonnÃ©es source

- **SIRENE â€“ StockEtablissement**
- Source : INSEE / data.gouv.fr
- Format : CSV UTF-8 (~8,8 Go dÃ©compressÃ©)

Fichier attendu :

data/raw/StockEtablissement_utf8.csv


Les donnÃ©es ne sont **pas versionnÃ©es**.

---

## ğŸ” Filtrage dÃ©partement 44

Le script `ingest/filter_sirene_44.py` :
- lit le CSV SIRENE complet
- filtre sur `codePostalEtablissement LIKE '44%'`
- produit un CSV rÃ©duit

Sortie :

data/processed/sirene_44.csv


---

## ğŸ—„ï¸ Base de donnÃ©es

- Base PostgreSQL hÃ©bergÃ©e sur **Supabase**
- Table brute : `sirene_44` (colonnes TEXT, schÃ©ma issu du CSV)
- Transformations rÃ©alisÃ©es via **vues SQL**

---

## ğŸ§¼ Vue clean

Vue : `v_sirene_44`

- noms en `snake_case`
- chaÃ®nes vides converties en `NULL`
- usage SQL sans guillemets

DÃ©finition :

sql/001_view_v_sirene_44.sql


---

## ğŸ“Š Vue analytics

Vue : `v_sirene_44_analytics`

- typage logique
- indicateurs calculÃ©s (`is_actif`, validitÃ© SIRET, dÃ©partement)
- base prÃªte pour BI / dashboards

DÃ©finition :

sql/020_view_v_sirene_44_analytics.sql


---

## ğŸ§ª Data Quality

### Checks analytiques
Fichier :

sql/010_dq_checks.sql


ContrÃ´les :
- volumÃ©trie
- cohÃ©rence dÃ©partement
- complÃ©tude
- format & unicitÃ© SIRET
- rÃ©partition actifs / fermÃ©s

### Monitoring structurÃ©
- Table : `dq_results`
- RÃ¨gles exÃ©cutÃ©es via `sql/031_run_dq_rules.sql`
- RÃ©sultat : mÃ©trique, seuil, statut `OK / KO`, timestamp

---

## ğŸ•’ Historisation des imports

Table :

sirene_import_runs


Chaque import enregistre :
- date dâ€™import
- fichier source
- nombre de lignes

---

## ğŸ“ˆ Vue Data Quality par import

Vue :

v_dq_by_import


Cette vue associe chaque import Ã  la **derniÃ¨re exÃ©cution DQ connue**, avec :
- une ligne par rÃ¨gle
- un statut exploitable en BI

DÃ©finition :

sql/050_view_v_dq_by_import.sql


---

## â–¶ï¸ ExÃ©cution du pipeline complet

Un script unique permet de rejouer lâ€™ensemble du pipeline :

```bash
bash scripts/run_pipeline.sh

Ã‰tapes incluses :

    filtrage CSV

    import Supabase

    vues SQL

    rÃ¨gles Data Quality

    historisation de lâ€™import

ğŸ§  Choix techniques

    PostgreSQL (Supabase) : gratuit, fiable, SQL natif

    COPY PostgreSQL : performant sur gros volumes

    Table brute + vues : sÃ©paration ingestion / logique mÃ©tier

    Monitoring SQL versionnÃ© : explicite, traÃ§able, outillÃ©